{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Connect With Me in Linkedin  :-** https://www.linkedin.com/in/dheerajkumar1997/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving Knowledge as Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = \"\"\"DATA : It can be any unprocessed fact, value, text, sound or picture that is not being interpreted and analyzed. \n",
    "Data is the most important part of all Data Analytics, Machine Learning, Artificial Intelligence. Without data, we can’t train \n",
    "any model and all modern research and automation will go vain. Big Enterprises are spending loads of money just to gather as \n",
    "much certain data as possible.Example: Why did Facebook acquire WhatsApp by paying a huge price of $19 billion?\n",
    "The answer is very simple and logical – it is to have access to the users’ information that Facebook may not have but WhatsApp\n",
    "will have. This information of their users is of paramount importance to Facebook as it will facilitate the task of improvement \n",
    "in their services.INFORMATION : Data that has been interpreted and manipulated and has now some meaningful inference for the users.\n",
    "KNOWLEDGE : Combination of inferred information, experiences, learning and insights. Results in awareness or concept building \n",
    "for an individual or organization.Consider an example:There’s a Shopping Mart Owner who conducted a survey for which he has a long \n",
    "list of questions and answers that he had asked from the customers, this list of questions and answers is DATA. Now every time when \n",
    "he want to infer anything and can’t just go through each and every question of thousands of customers to find something \n",
    "relevant as it would be time-consuming and not helpful. In order to reduce this overhead and time wastage and to make work \n",
    "easier, data is manipulated through software, calculations, graphs etc. as per own convenience, this inference from \n",
    "manipulated data is Information. So, Data is must for Information. Now Knowledge has its role in differentiating \n",
    "between two individuals having same information. Knowledge is actually not a technical content but is linked to human thought\n",
    "process\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data unprocess fact valu text sound pictur interpret analyz',\n",
       " 'data import part data analyt machin learn artifici intellig',\n",
       " 'without data train model modern research autom go vain',\n",
       " 'big enterpris spend load money gather much certain data possibl exampl facebook acquir whatsapp pay huge price billion',\n",
       " 'answer simpl logic access user inform facebook may whatsapp',\n",
       " 'inform user paramount import facebook facilit task improv servic inform data interpret manipul meaning infer user',\n",
       " 'knowledg combin infer inform experi learn insight',\n",
       " 'result awar concept build individu organ consid exampl shop mart owner conduct survey long list question answer ask custom list question answer data',\n",
       " 'everi time want infer anyth go everi question thousand custom find someth relev would time consum help',\n",
       " 'order reduc overhead time wastag make work easier data manipul softwar calcul graph etc',\n",
       " 'per conveni infer manipul data inform',\n",
       " 'data must inform',\n",
       " 'knowledg role differenti two individu inform',\n",
       " 'knowledg actual technic content link human thought process']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(Corpus)\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "corpus  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus).toarray()\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 112)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Connect With Me in Linkedin  :-** https://www.linkedin.com/in/dheerajkumar1997/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
